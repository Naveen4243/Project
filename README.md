# ğŸ“š TDS Virtual TA Scraper

A simple scraper tool to extract content from the **Tools of Data Science (TDS)** course website and Discourse forum, saving them as markdown files with metadata for offline study and analysis.  
This project was built as part of the **IIT Madras BSc Data Science program.**

---

## ğŸ“Œ Project Repository

ğŸ”— [GitHub Repository](https://github.com/Naveen4243/Project)  
ğŸ‘¤ GitHub: [Naveen4243](https://github.com/Naveen4243)

---

## ğŸ“ Project Structure
```
project/
â”œâ”€â”€ scrapers/
â”‚ â”œâ”€â”€ discourse_scraper.py
â”‚ â””â”€â”€ html_scraper.py
â”œâ”€â”€ markdown_files/
â”‚ â””â”€â”€ Tools_in_Data_Science.md
â”œâ”€â”€ discourse_posts.json
â”œâ”€â”€ metadata.json
â”œâ”€â”€ package-lock.json
â”œâ”€â”€ package.json
â”œâ”€â”€ project-tds-virtual-ta-promptfoo.yaml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ auth.json
â”œâ”€â”€ main.py
â”œâ”€â”€ sample.webp
â”œâ”€â”€ image.txt
â”œâ”€â”€ received_image.webp
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## ğŸ“¦ Installation

1. **Clone this repository**

```bash
git clone https://github.com/Naveen4243/Project.git
cd Project
```

2. **Install dependencies**

```bash
pip install -r requirements.txt
```

3. **Install Playwright Browsers (only needed once)**

```bash
playwright install
```
---

## ğŸš€ How to Use
1. **Scrape Discourse Posts**

Run:
```bash
python scrapers/discourse_scraper.py
```

â— On first run â€” it will launch a browser window.

ğŸ‘‰ Login with your Google IITM student email.

ğŸ‘‰ Then click â–¶ï¸ Resume in the Playwright control bar.

ğŸ‘‰ Itâ€™ll save your session to auth.json for future runs.

After login, itâ€™ll scrape and create:

âœ… discourse_posts.json â€” containing clean structured posts from 01 Jan 2025 to 14 Apr 2025.


2. **Scrape TDS Course Pages**

Run:
```bash
python scrapers/html_scraper.py
```

This will:

ğŸ‘‰ Visit each page in the TDS course site

ğŸ‘‰ Convert content to Markdown

ğŸ‘‰ Save it in the markdown_files/ folder

ğŸ‘‰ Log metadata into metadata.json

---

## Create and Run the FastAPI-based Virtual TA API

The API serves as a question-answer interface using the scraped metadata and supports optional image upload.

1. **Start the API server**

 ```bash
uvicorn main:app --reload
```

2. **API Endpoints**

GET /
Returns a welcome message.

POST /api/
Accepts JSON body with:

```json
{
  "question": "Your question here",
  "image": "Optional base64-encoded image string"
}
```

---

## Evaluation part
Load the question and expected URL in YAML and 
Run:
```bash
npx -y promptfoo eval --config project-tds-virtual-ta-promptfoo.yaml
```
---

## ğŸ“Œ Notes

ğŸ‘‰ Make sure the metadata.json and markdown_files/ are present before running the API.

ğŸ‘‰ The API currently performs keyword matching in the metadata titles to find relevant resources.

ğŸ‘‰ The image upload is optional and stored as received_image.webp for further development.

---

## ğŸ“– License

This project is for educational use as part of the IIT Madras BSc Data Science - Tools of Data Science course.

---

## âœ¨ Author
**Naveen Raj R**
